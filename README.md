# ü§ñ AI Agentic Sales Intelligence System

**Developer:** Basudab Chowdhury Raj  
**Architecture:** LangChain + LangGraph + Groq  
**Status:** üü¢ Online  
**[Try the App Here](https://akij-sales-agent.streamlit.app/)**

---

## üìò Project Overview
The **AI Agentic Sales Intelligence System** is an advanced, modular framework that leverages **agentic reasoning, retrieval-augmented generation (RAG), and real-time analytics** to automate sales data insights and business intelligence.

Built on **LangChain** and **LangGraph**, the system orchestrates multiple reasoning layers‚Äîeach responsible for data retrieval, interpretation, and decision-making. It uses **Groq inference acceleration** for ultra-fast LLM responses, enabling near real-time analytics and intelligent task execution.

[![Watch the Demo](assets/salesagent.png)](https://drive.google.com/file/d/1t2FvVGvdRAaF7eC-pajXi-dC8RFYRiNL/view?usp=sharing)

---

## ‚öôÔ∏è Core Features
- üß© **Multi-Agent Architecture:** Autonomous agents for data analysis, summarization, and decision reasoning.  
- üîó **LangGraph Workflow:** Graph-based orchestration for controlled agent interactions and dependency tracking.  
- ‚ö° **Groq-Optimized Inference:** Accelerated LLM processing for low-latency reasoning.  
- üóÇÔ∏è **Retrieval-Augmented Generation (RAG):** Integrates structured and unstructured sales data.  
- üìä **4-Tier Analytics Layers:**  
  1. **Descriptive Analytics** ‚Äì Summarize ‚Äúwhat happened‚Äù  
  2. **Diagnostic Analytics** ‚Äì Explain ‚Äúwhy it happened‚Äù  
  3. **Predictive Analytics** ‚Äì Forecast ‚Äúwhat will happen‚Äù  
  4. **Prescriptive Analytics** ‚Äì Recommend ‚Äúwhat should be done‚Äù  
- üß† **Memory & Context Retention:** Enables agents to maintain historical context across sessions.

---

## üõ†Ô∏è Tech Stack
- **Languages & Frameworks:** Python, Streamlit  
- **AI Orchestration:** LangChain, LangGraph  
- **LLM Engines:** Groq, OpenAI / Anthropic APIs  
- **Data & Analytics:** Pandas, NumPy, scikit-learn, Plotly  
- **Database / Vector Stores:** FAISS or ChromaDB (for RAG)  

---

## üöÄ Vision
This project demonstrates how **agentic intelligence** can transform traditional data pipelines into **autonomous insight systems** ‚Äî empowering teams to make faster, smarter business decisions.

---

## üéØ Overview

The Sales Agent System is a sophisticated data analysis platform that applies four layers of analytics to hierarchical sales data:

1. **Descriptive** - "What happened?" ‚Üí KPIs, aggregations, trends
2. **Diagnostic** - "Why did it happen?" ‚Üí Root cause analysis, anomalies
3. **Predictive** - "What will happen?" ‚Üí 14-day sales forecast
4. **Prescriptive** - "What should be done?" ‚Üí Actionable recommendations

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Streamlit UI                         ‚îÇ
‚îÇ                  (User Interface)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              LangGraph Orchestrator                     ‚îÇ
‚îÇ            (Groq LLM Coordination)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì             ‚Üì             ‚Üì            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Descriptive  ‚îÇ ‚îÇDiagnostic‚îÇ ‚îÇPredictive‚îÇ ‚îÇPrescriptive‚îÇ
‚îÇ    Agent     ‚îÇ ‚îÇ  Agent   ‚îÇ ‚îÇ  Agent   ‚îÇ ‚îÇ   Agent   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ             ‚îÇ             ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ  Analytics   ‚îÇ
              ‚îÇ   Engine     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ Sales Data   ‚îÇ
              ‚îÇ    (CSV)     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure

```
sales_agent_system/
‚îÇ
‚îú‚îÄ‚îÄ app.py                          # Streamlit UI
‚îú‚îÄ‚îÄ orchestrator.py                 # LangGraph orchestrator
‚îú‚îÄ‚îÄ groq_llm.py                     # Groq LLM wrapper
‚îú‚îÄ‚îÄ tools_agents.py                 # LangChain tool wrappers
‚îú‚îÄ‚îÄ analytics.py                    # Core analytics logic
‚îú‚îÄ‚îÄ sample_data.py                  # Dataset generator
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator_prompt.txt     # LLM system prompt
‚îî‚îÄ‚îÄ README.md                       # This file
```

## üöÄ Quick Start

### 1. Installation

```bash
# Clone or create project directory
mkdir sales_agent_system
cd sales_agent_system

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Generate Sample Data

```bash
python sample_data.py
```

This creates `sales_sample.csv` with 120 days of synthetic sales data across:
- 4 Products (Product_A, Product_B, Product_C, Product_D)
- 3 Segments (Consumer, Corporate, Home_Office)
- 4 Regions (East, West, North, South)
- 3 Channels (Online, Retail, Direct)

### 3. Set Up Groq API (Optional)

```bash
# Set environment variable
export GROQ_API_KEY="your_groq_api_key_here"

# Or create .env file
echo "GROQ_API_KEY=your_key_here" > .env
```

**Note:** The system works without a Groq API key using mock LLM responses.

### 4. Run the Application

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## üíª Usage

### Basic Analysis

1. **Enter your query** in the chat interface:
   - "Analyze last 30 days for all regions"
   - "Show me sales performance by region"
   - "What are the trends and forecasts?"

2. **Configure filters** in the sidebar:
   - Date range (From/To)
   - Region filter (optional)

3. **Click "Run Analysis"** to execute the full pipeline

4. **View results** across five tabs:
   - **Descriptive**: KPIs, charts, time series
   - **Diagnostic**: Root causes, insights, anomalies
   - **Predictive**: 14-day forecast with confidence intervals
   - **Prescriptive**: Actionable recommendations
   - **Summary**: Executive summary and explainability

### Example Queries

```
"Analyze sales for October 2025"
"What's driving the decline in the East region?"
"Forecast next 14 days and suggest actions"
"Compare performance across all channels"
```

## üìä Output Format

The system returns structured JSON with all analysis layers:

```json
{
  "descriptive": {
    "total_sales": 98000.50,
    "avg_daily_sales": 3266.68,
    "by_region": {
      "West": 28500.00,
      "North": 26000.00,
      "South": 24500.00,
      "East": 19000.00
    },
    "time_series": [...]
  },
  "diagnostic": {
    "best_region": "West",
    "worst_region": "East",
    "insights": [
      {
        "entity": "East",
        "root_cause": "Heavy reliance on Retail channel (65%)",
        "confidence": 0.82
      }
    ]
  },
  "predictive": {
    "forecast_days": 14,
    "forecast_values": [3500, 3600, 3450, ...],
    "total_forecast": 49200.00
  },
  "prescriptive": {
    "actions": [
      {
        "action": "Increase marketing budget in East region by 25%",
        "rationale": "East is underperforming. Boost visibility.",
        "priority": "high",
        "confidence": 0.82
      }
    ]
  },
  "explainability": [...]
}
```

## üîß Configuration

### Environment Variables

```bash
GROQ_API_KEY=your_api_key        # Optional: Groq API key
```

### Customization

**Change forecast period:**
```python
# In analytics.py
def predictive_forecast(df, forecast_days=30)  # Default is 14
```

**Modify data generation:**
```python
# In sample_data.py
generate_sales_data(days=180)  # Generate 180 days instead of 120
```

**Adjust LLM parameters:**
```python
# In groq_llm.py
GroqLLM(
    model="llama3-70b-8192",  # Change model
    temperature=0.2,          # Adjust creativity
    max_tokens=3000           # Increase response length
)
```

## üß™ Testing

### Test Individual Components

```python
# Test analytics engine
from analytics import descriptive_summary, diagnostic_analysis
from sample_data import load_sales_data

df = load_sales_data()
result = descriptive_summary(df)
print(result)

# Test orchestrator
from orchestrator import build_agent_system

agent = build_agent_system(df)
output = agent.analyze("Analyze last 30 days")
print(output)
```

### Run with Mock Data

The system automatically generates sample data if `sales_sample.csv` doesn't exist.

## üìà Features

### Current Features

‚úÖ Four-layer analytics pipeline  
‚úÖ LangGraph orchestration  
‚úÖ Groq LLM integration  
‚úÖ Interactive Streamlit UI  
‚úÖ Real-time visualizations (Plotly)  
‚úÖ Export to JSON/CSV  
‚úÖ Confidence scoring  
‚úÖ Explainability layer  

### Optional Add-ons (Future)

- [ ] PDF report generation (reportlab)
- [ ] LangGraph workflow visualization
- [ ] OpenAI/Anthropic fallback models
- [ ] SQLite conversation logging
- [ ] Multi-user authentication
- [ ] Real-time data streaming
- [ ] Custom agent plugins

## üõ†Ô∏è Troubleshooting

### Common Issues

**Issue**: `ImportError: No module named 'groq'`  
**Solution**: Install dependencies: `pip install -r requirements.txt`

**Issue**: Missing `sales_sample.csv`  
**Solution**: Run `python sample_data.py` to generate data

**Issue**: Groq API errors  
**Solution**: Check API key or use system without key (mock mode)

**Issue**: Streamlit not starting  
**Solution**: Ensure port 8501 is free or specify another: `streamlit run app.py --server.port 8502`

## üìö Dependencies

| Library | Version | Purpose |
|---------|---------|---------|
| langchain | ‚â•0.1.0 | LLM orchestration framework |
| langgraph | ‚â•0.0.20 | Agent graph coordination |
| groq | ‚â•0.4.0 | Groq LLM client |
| pandas | ‚â•2.0.0 | Data manipulation |
| scikit-learn | ‚â•1.3.0 | Machine learning models |
| plotly | ‚â•5.18.0 | Interactive visualizations |
| streamlit | ‚â•1.29.0 | Web UI framework |

## ü§ù Contributing

Contributions welcome! Areas for improvement:

- Additional analytics methods (clustering, classification)
- More sophisticated forecasting models (LSTM, Prophet)
- Advanced LLM prompting strategies
- Performance optimizations
- Unit tests and integration tests

## üìù License

MIT License - feel free to use and modify for your projects.

## üôè Acknowledgments

Built with:
- [LangChain](https://langchain.com) - LLM application framework
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent orchestration
- [Groq](https://groq.com) - Fast LLM inference
- [Streamlit](https://streamlit.io) - Interactive web apps

## üìß Support
- [Linkedin](https://www.linkedin.com/in/basudab007/) - Connect me
- [Portfolio](https://basudabch.vercel.app/) - Check my profile

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check documentation at [LangChain Docs](https://docs.langchain.com)
- Review Groq API documentation

---

**Happy Analyzing! üìäüöÄ**
